{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "39f31e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"P-SET\"\n",
    "llm_type = \"llama3.1:70b\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd235189",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "import numpy as np\n",
    "\n",
    "def plot_confusion_matrices_for_column_pairs(df, gt_col,vis_columns):\n",
    "\n",
    "    n_pairs = len(vis_columns)\n",
    "\n",
    "    # Determine layout: square-ish grid\n",
    "    n_cols = int(np.ceil(np.sqrt(n_pairs)))\n",
    "    n_rows = int(np.ceil(n_pairs / n_cols))\n",
    "\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(5 * n_cols, 5 * n_rows))\n",
    "    axes = axes.flatten()\n",
    "    col1 = gt_col\n",
    "    for idx, col2 in enumerate(vis_columns):\n",
    "        ax = axes[idx]\n",
    "        \n",
    "        # Drop rows with missing values in either column\n",
    "        sub_df = df[[col1, col2]].dropna().copy()\n",
    "        start_length = len(sub_df)\n",
    "        # sub_df = sub_df[sub_df.apply(lambda x: True if (\"_\" not in x[col1] and '_' not in x[col2]) else False, axis=1)]\n",
    "        filter_length = len(sub_df)\n",
    "        # Get confusion matrix\n",
    "        labels = sorted(set(sub_df[col1]) | set(sub_df[col2]))\n",
    "        cm = confusion_matrix(sub_df[col1], sub_df[col2], labels=labels)\n",
    "\n",
    "        # Plot heatmap\n",
    "        sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=labels, yticklabels=labels, ax=ax)\n",
    "        ax.set_title(f\"{col1} vs \\n{col2}\\n strt: {start_length}\\nelim.:{filter_length-start_length}\", fontsize=10)\n",
    "        ax.set_xlabel(col2)\n",
    "        ax.set_ylabel(col1)\n",
    "\n",
    "    # Hide any extra axes\n",
    "    for j in range(len(vis_columns), len(axes)):\n",
    "        fig.delaxes(axes[j])\n",
    "\n",
    "    fig.tight_layout()\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe6b3a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************Sleep************************\n",
      "['../exports/05_llm_llama3.1:70b_P-SET/Sleep/Sleep_Documents_att_False.pkl', '../exports/05_llm_llama3.1:70b_P-SET/Sleep/Sleep_Documents_att_True.pkl', '../exports/05_llm_llama3.1:70b_P-SET/Sleep/Sleep_Sentences_att_False.pkl', '../exports/05_llm_llama3.1:70b_P-SET/Sleep/Sleep_Sentences_att_True.pkl']\n",
      "Sleep_Documents_att_False\n",
      " False Sleep_Documents_att_False\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'UID'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/tactics_storage/projects/llm_text_to_event/.venv/lib/python3.10/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3811\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mpandas/_libs/index.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/index.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'UID'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 101\u001b[0m\n\u001b[1;32m     96\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(output_folder,exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    100\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_pickle(file)\n\u001b[0;32m--> 101\u001b[0m df[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mET\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_time\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mUID\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x:id_to_dict_time\u001b[38;5;241m.\u001b[39mget(x))\n\u001b[1;32m    102\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfocus_event\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m ET\n\u001b[1;32m    105\u001b[0m df[gt_column] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUID\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x:id_to_gt\u001b[38;5;241m.\u001b[39mget(x))\n",
      "File \u001b[0;32m~/tactics_storage/projects/llm_text_to_event/.venv/lib/python3.10/site-packages/pandas/core/frame.py:4107\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4106\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4107\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4109\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/tactics_storage/projects/llm_text_to_event/.venv/lib/python3.10/site-packages/pandas/core/indexes/base.py:3819\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3815\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3816\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3817\u001b[0m     ):\n\u001b[1;32m   3818\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3819\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3820\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3821\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3822\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3823\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'UID'"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "from itertools import product\n",
    "disagreement_type = \"correct\"\n",
    "llm_type = \"llama3.1:70b\"\n",
    "def get_time(x):\n",
    "    x = np.array(x)\n",
    "    # Remove NaNs\n",
    "    x = x[~np.isnan(x)]\n",
    "    # If less than 3 values, just return mean\n",
    "    if len(x) < 3:\n",
    "        return np.mean(x)\n",
    "    # Remove outliers using IQR\n",
    "    q1, q3 = np.percentile(x, [25, 75])\n",
    "    iqr = q3 - q1\n",
    "    mask = (x >= q1 - 1.5 * iqr) & (x <= q3 + 1.5 * iqr)\n",
    "    return np.mean(x[mask])\n",
    "\n",
    "def fixnames(ls,suffix,remove):\n",
    "    LS=[]\n",
    "    for s in ls:\n",
    "        s = s.replace(\"_keyword_evidence\",\"_Ki\").replace(\"_example_evidence\",\"_Ei\").replace(\"_no_evidence\",\"\").replace(\"_all_evidence\",\"KiEi\").replace(\"Event_Name_\",'').replace(\"_Events\",'_').replace('_'+remove,\"\")\n",
    "        s = s + \"_\" + suffix\n",
    "        if \"sentence\" in s:\n",
    "            s = s.replace(\"sentence\",\"\")\n",
    "            s = s + \"_Sent-SET\"\n",
    "        elif \"document\" in s:\n",
    "            s = s.replace(\"document\",\"\")\n",
    "            s = s + \"_Doc-SET\"\n",
    "        LS.append(s)\n",
    "    return LS\n",
    "\n",
    "def get_col_suffix(keyword_input, example_input):\n",
    "    col_suffix = \"no\"\n",
    "    if keyword_input and example_input:\n",
    "        col_suffix = \"all\"\n",
    "    elif keyword_input and not example_input:\n",
    "        col_suffix = \"keyword\"\n",
    "    elif not keyword_input and example_input:\n",
    "        col_suffix = \"example\"\n",
    "    return col_suffix\n",
    "\n",
    "LLM_dict = {}\n",
    "llm_models = []\n",
    "for keyword_input, example_input in [i for i in product([True,False],[True,False])]: \n",
    "    for input_type in [\"sentence\", \"document\"]:\n",
    "        col_suffix = get_col_suffix(keyword_input, example_input)\n",
    "        llm_models.append(f\"LLM_Events_{col_suffix}_evidence_{input_type}\")\n",
    "df_both = pd.read_pickle(\"../exports/04_dictionary_features.pkl\")\n",
    "\n",
    "dataset = \"P-SET\"\n",
    "for analysis_type in [\"all\"]: #(M-SET, A-SET, D-SET, F-SET)\n",
    "    for ET in [\"Sleep\",\"Excretion\"]:\n",
    "        print(f\"********************{ET}************************\")\n",
    "        llm_files = glob(f\"../exports/05_llm_{llm_type}_{dataset}/{ET}/*.pkl\")\n",
    "        print(llm_files)\n",
    "        try:\n",
    "            gt_file_sent = glob(f\"../exports/04_groundtruth/{dataset}/Annotated/{ET}_Sentences.pkl\")[0]\n",
    "            gt_file_doc = glob(f\"../exports/04_groundtruth/{dataset}/Annotated/{ET}_Documents.pkl\")[0]\n",
    "        except IndexError:\n",
    "            print(f\"No ground truth file found for {ET} in ../exports/04_groundtruth/{dataset}/Annotated/\")\n",
    "            continue    \n",
    "        \n",
    "        for file in llm_files:\n",
    "            filename = os.path.basename(file).rstrip('.pkl')\n",
    "            print(filename)\n",
    "            text_type = \"Document\" if \"Document\" in filename else \"Sentence\"\n",
    "            _,attribute_requested = filename.split(\"_\")[-2:]\n",
    "            attribute_requested = eval(attribute_requested)\n",
    "            suffix = \"Ao\" if attribute_requested else \"\"           \n",
    "            print(suffix,attribute_requested,filename)\n",
    "            \n",
    "            if text_type == \"Sentence\":\n",
    "                gt_file = gt_file_sent\n",
    "                id_type = id_type\n",
    "                gt_column = f\"Sent_gt_{ET}\"\n",
    "            elif text_type == \"Document\":\n",
    "                gt_file = gt_file_doc\n",
    "                id_type = \"ROW_ID\"\n",
    "                gt_column = f\"Doc_gt_{ET}\"\n",
    "            gt_df = pd.read_pickle(gt_file)\n",
    "            gt_df = gt_df.dropna(subset=gt_column)\n",
    "            gt_df['Lemma'] = gt_df['Lemma'].apply(lambda x: tuple(x))\n",
    "            gt_df[\"is_keyword_present\"] = gt_df[\"Keyword\"].apply(lambda x: 0 if x[0]=='' else 1)\n",
    "            # gt_df = gt_df.groupby(id_type)[[ gt_column, \"is_keyword_present\", text_type,\"Lemma\"]].agg(lambda x: max(x) if len(set(x))>1 else set(x).pop()).reset_index()\n",
    "            id_to_gt = {row[id_type]:row[gt_column] for _,row in gt_df.iterrows()}\n",
    "            id_to_key_present = {row[id_type]:row[f\"is_keyword_present\"] for _,row in gt_df.iterrows()}\n",
    "            id_to_lemma = {row[id_type]:row[f\"Lemma\"] for _,row in gt_df.iterrows()}\n",
    "            id_to_dict_time = {row[id_type]:row[f\"Time\"] for _,row in df_both.iterrows()}\n",
    "            output_folder = f\"../exports/06_analysis/{ET}\"\n",
    "            os.makedirs(output_folder,exist_ok=True)\n",
    "       \n",
    "            \n",
    "            \n",
    "            df = pd.read_pickle(file)\n",
    "            df[f'{ET}_time'] = df[id_type].apply(lambda x:id_to_dict_time.get(x))\n",
    "            df[\"focus_event\"] = ET\n",
    "            \n",
    "            \n",
    "            df[gt_column] = df[id_type].apply(lambda x:id_to_gt.get(x))\n",
    "            \n",
    "            df[f\"is_keyword_present\"] = df[id_type].apply(lambda x:id_to_key_present.get(x))\n",
    "            display(df.is_keyword_present.value_counts())\n",
    "            \n",
    "            print(df[[gt_column,\"is_keyword_present\"]].value_counts())\n",
    "                        \n",
    "            df[f\"dict_Lemma\"] = df[id_type].apply(lambda x:id_to_lemma.get(x))\n",
    "            df.dropna(subset=gt_column,inplace=True)\n",
    "            df[gt_column] = df[gt_column].astype(int)\n",
    "\n",
    "            for col in llm_models:\n",
    "                df[f\"{col}_{ET}_time\"] = df[col].apply(lambda x:x['event_detection_time'])\n",
    "            if len(df) > 1:\n",
    "                first_row = df.iloc[0]\n",
    "                splittable_columns = [\"Event_Name\"]+[f\"Event_Name_{model}\" for model in llm_models]\n",
    "                disagreement_dfs = []\n",
    "                generated_columns = []\n",
    "\n",
    "                for col in splittable_columns:\n",
    "                    generated_column = f\"{col}_{ET}\"\n",
    "                    df[generated_column] = df[col].apply(lambda x: 1 if ET in x else 0)\n",
    "                    \n",
    "                    generated_columns.append(generated_column)\n",
    "                \n",
    "                f1s, accs, precs, recs, psup, nsup, times, tp, tn, fp, fn = [],[],[],[],[],[],[],[],[],[],[]\n",
    "                \n",
    "                \n",
    "                for col in generated_columns:\n",
    "                    df_temp = df.copy()\n",
    "                    y_gt = df_temp[gt_column]\n",
    "                    LLM_dict[(attribute_requested,gt_column)] = y_gt\n",
    "                    preds = df_temp[col]\n",
    "                    LLM_dict[(attribute_requested,col)] = preds\n",
    "                    f1s.append(f1_score(y_gt, preds))\n",
    "                    accs.append(accuracy_score(y_gt, preds))\n",
    "                    precs.append(precision_score(y_gt, preds, zero_division=0))\n",
    "                    recs.append(recall_score(y_gt, preds))   \n",
    "                    psup.append(sum(y_gt))\n",
    "                    nsup.append(sum(y_gt==0))\n",
    "                    times.append(get_time(df_temp[f\"{col.lstrip('Event_Name_')}_time\"]))\n",
    "                    #true positive\n",
    "                    tn_i, fp_i, fn_i, tp_i = confusion_matrix(y_gt, preds).ravel()\n",
    "                    tp.append(tp_i)\n",
    "                    tn.append(tn_i)\n",
    "                    fp.append(fp_i)\n",
    "                    fn.append(fn_i)\n",
    "                \n",
    "            \n",
    "                results_df = {\"col_name\":generated_columns, \"technique\":fixnames(generated_columns,suffix,ET), \"pos_sup\": psup, \"neg_sup\": nsup, \"f1_score\":f1s, \"precision\":precs, \"recall\":recs, \"TP\":tp, 'TN':tn, 'FP':fp, 'FN':fn, \"time\":times} \n",
    "                results = pd.DataFrame(results_df)   \n",
    "                plot_confusion_matrices_for_column_pairs(df, gt_column,vis_columns=generated_columns)\n",
    "                op_path = f\"{output_folder}/{analysis_type}_{disagreement_type}_{filename}.xlsx\"\n",
    "\n",
    "\n",
    "                # df.to_excel(op_path,index=False)\n",
    "                print(f\"file written to {op_path}\")\n",
    "                display(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f5b05b3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Event_Name\n",
       "[Pain, Family, Unknown]                              2\n",
       "[Pain, Sleep, Family, Unknown]                       2\n",
       "[Pain, Sleep, Unknown]                               2\n",
       "[Pain, Unknown]                                      2\n",
       "[Eating, Unknown, Excretion, Family, Sleep]          2\n",
       "[Family, Sleep, Pain, Unknown]                       2\n",
       "[Pain, Unknown, Excretion, Family, Sleep]            1\n",
       "[Pain, Sleep, Unknown, Excretion]                    1\n",
       "[Family, Eating, Unknown]                            1\n",
       "[Family, Sleep, Unknown]                             1\n",
       "[Pain, Eating, Unknown, Excretion, Family, Sleep]    1\n",
       "[Family, Unknown]                                    1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_df.Event_Name.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "02ea0800",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Event_Name_Sleep'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6944b9ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1277038: 0,\n",
       " 1277048: 1,\n",
       " 1277049: 0,\n",
       " 1277050: 0,\n",
       " 1277051: 1,\n",
       " 1277052: 0,\n",
       " 1277053: 0,\n",
       " 1277054: 0,\n",
       " 1277055: 0,\n",
       " 1277056: 0,\n",
       " 1277057: 0,\n",
       " 1277058: 0,\n",
       " 1277059: 0,\n",
       " 1277060: 1,\n",
       " 1277061: 0,\n",
       " 1277062: 0}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9184bab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ROW_ID', 'SUBJECT_ID', 'HADM_ID', 'CHARTDATE', 'CHARTTIME',\n",
       "       'STORETIME', 'CATEGORY', 'DESCRIPTION', 'CGID', 'ISERROR', 'DOCUMENT',\n",
       "       'AGE', 'LOS_DAYS', 'IS_ALIVE', 'DOCUMENT_LOWER', 'NUM_NOTES',\n",
       "       'MAX_NOTES_PER_DAY', 'MAX_NOTES_PER_CHARTTIME', 'all_dates_present',\n",
       "       'Sentences', 'Sentences_Raw', 'Sentences_Cleaned', 'Events', 'Sent_ID',\n",
       "       'UID', 'Event_Name', 'Sentence', 'Time', 'Keyword', 'Lemma',\n",
       "       'Keyword_Position', 'LLM_Events_all_evidence_sentence',\n",
       "       'Event_Name_LLM_Events_all_evidence_sentence',\n",
       "       'Attribute_LLM_Events_all_evidence_sentence',\n",
       "       'LLM_Events_keyword_evidence_sentence',\n",
       "       'Event_Name_LLM_Events_keyword_evidence_sentence',\n",
       "       'Attribute_LLM_Events_keyword_evidence_sentence',\n",
       "       'LLM_Events_example_evidence_sentence',\n",
       "       'Event_Name_LLM_Events_example_evidence_sentence',\n",
       "       'Attribute_LLM_Events_example_evidence_sentence',\n",
       "       'LLM_Events_no_evidence_sentence',\n",
       "       'Event_Name_LLM_Events_no_evidence_sentence',\n",
       "       'Attribute_LLM_Events_no_evidence_sentence',\n",
       "       'LLM_Events_all_evidence_document',\n",
       "       'Event_Name_LLM_Events_all_evidence_document',\n",
       "       'Attribute_LLM_Events_all_evidence_document',\n",
       "       'LLM_Events_keyword_evidence_document',\n",
       "       'Event_Name_LLM_Events_keyword_evidence_document',\n",
       "       'Attribute_LLM_Events_keyword_evidence_document',\n",
       "       'LLM_Events_example_evidence_document',\n",
       "       'Event_Name_LLM_Events_example_evidence_document',\n",
       "       'Attribute_LLM_Events_example_evidence_document',\n",
       "       'LLM_Events_no_evidence_document',\n",
       "       'Event_Name_LLM_Events_no_evidence_document',\n",
       "       'Attribute_LLM_Events_no_evidence_document', 'Sleep_time',\n",
       "       'focus_event', 'GT_Sleep', 'is_keyword_present', 'dict_Lemma',\n",
       "       'LLM_Events_all_evidence_sentence_Sleep_time',\n",
       "       'LLM_Events_all_evidence_document_Sleep_time',\n",
       "       'LLM_Events_keyword_evidence_sentence_Sleep_time',\n",
       "       'LLM_Events_keyword_evidence_document_Sleep_time',\n",
       "       'LLM_Events_example_evidence_sentence_Sleep_time',\n",
       "       'LLM_Events_example_evidence_document_Sleep_time',\n",
       "       'LLM_Events_no_evidence_sentence_Sleep_time',\n",
       "       'LLM_Events_no_evidence_document_Sleep_time', 'Event_Name_Sleep',\n",
       "       'Event_Name_LLM_Events_all_evidence_sentence_Sleep',\n",
       "       'Event_Name_LLM_Events_all_evidence_document_Sleep',\n",
       "       'Event_Name_LLM_Events_keyword_evidence_sentence_Sleep',\n",
       "       'Event_Name_LLM_Events_keyword_evidence_document_Sleep',\n",
       "       'Event_Name_LLM_Events_example_evidence_sentence_Sleep',\n",
       "       'Event_Name_LLM_Events_example_evidence_document_Sleep',\n",
       "       'Event_Name_LLM_Events_no_evidence_sentence_Sleep',\n",
       "       'Event_Name_LLM_Events_no_evidence_document_Sleep'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec7b2a42",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Event_Name_LLM_Events_keyword_evidence_document_Ao'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mDOCUMENT\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mEvent_Name_LLM_Events_keyword_evidence_document_Ao\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mSentence\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mGT_Sleep\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m.to_excel(\u001b[33m\"\u001b[39m\u001b[33m../exports/temp_result.xlsx\u001b[39m\u001b[33m\"\u001b[39m,index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm_text_to_event/.venv/lib/python3.12/site-packages/pandas/core/frame.py:4113\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4111\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[32m   4112\u001b[39m         key = \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[32m-> \u001b[39m\u001b[32m4113\u001b[39m     indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcolumns\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[32m1\u001b[39m]\n\u001b[32m   4115\u001b[39m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[32m   4116\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) == \u001b[38;5;28mbool\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm_text_to_event/.venv/lib/python3.12/site-packages/pandas/core/indexes/base.py:6212\u001b[39m, in \u001b[36mIndex._get_indexer_strict\u001b[39m\u001b[34m(self, key, axis_name)\u001b[39m\n\u001b[32m   6209\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   6210\u001b[39m     keyarr, indexer, new_indexer = \u001b[38;5;28mself\u001b[39m._reindex_non_unique(keyarr)\n\u001b[32m-> \u001b[39m\u001b[32m6212\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6214\u001b[39m keyarr = \u001b[38;5;28mself\u001b[39m.take(indexer)\n\u001b[32m   6215\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[32m   6216\u001b[39m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm_text_to_event/.venv/lib/python3.12/site-packages/pandas/core/indexes/base.py:6264\u001b[39m, in \u001b[36mIndex._raise_if_missing\u001b[39m\u001b[34m(self, key, indexer, axis_name)\u001b[39m\n\u001b[32m   6261\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   6263\u001b[39m not_found = \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask.nonzero()[\u001b[32m0\u001b[39m]].unique())\n\u001b[32m-> \u001b[39m\u001b[32m6264\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not in index\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyError\u001b[39m: \"['Event_Name_LLM_Events_keyword_evidence_document_Ao'] not in index\""
     ]
    }
   ],
   "source": [
    "df[[\"DOCUMENT\",\"Event_Name_LLM_Events_keyword_evidence_document_Ao\",\"Sentence\" ,\"GT_Sleep\"]].to_excel(\"../exports/temp_result.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38140d36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False,\n",
       " ['LLM_Events_all_evidence_sentence',\n",
       "  'LLM_Events_all_evidence_document',\n",
       "  'LLM_Events_keyword_evidence_sentence',\n",
       "  'LLM_Events_keyword_evidence_document',\n",
       "  'LLM_Events_example_evidence_sentence',\n",
       "  'LLM_Events_example_evidence_document',\n",
       "  'LLM_Events_no_evidence_sentence',\n",
       "  'LLM_Events_no_evidence_document'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'dictionary_Sleep_time' in df.columns, llm_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3aff31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GT_Sleep\n",
       "0    297\n",
       "1      3\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_gt.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33c948e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591822ad",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "['gt_Excretion']",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[32m/scratch-local/74866/ipykernel_1386909/3166432436.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      1\u001b[39m gt_df = pd.read_pickle(gt_file)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m gt_df = gt_df.dropna(subset=f\"gt_{ET}\")\n\u001b[32m      3\u001b[39m gt_df[\u001b[33m\"Keyword\"\u001b[39m],gt_df[\u001b[33m\"Keyword\"\u001b[39m].apply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[32m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m x[\u001b[32m0\u001b[39m]==\u001b[33m''\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m1\u001b[39m).value_counts()\n",
      "\u001b[32m~/projects/llm_text_to_event/.venv/lib/python3.12/site-packages/pandas/core/frame.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, axis, how, thresh, subset, inplace, ignore_index)\u001b[39m\n\u001b[32m   6673\u001b[39m             ax = self._get_axis(agg_axis)\n\u001b[32m   6674\u001b[39m             indices = ax.get_indexer_for(subset)\n\u001b[32m   6675\u001b[39m             check = indices == -\u001b[32m1\u001b[39m\n\u001b[32m   6676\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m check.any():\n\u001b[32m-> \u001b[39m\u001b[32m6677\u001b[39m                 \u001b[38;5;28;01mraise\u001b[39;00m KeyError(np.array(subset)[check].tolist())\n\u001b[32m   6678\u001b[39m             agg_obj = self.take(indices, axis=agg_axis)\n\u001b[32m   6679\u001b[39m \n\u001b[32m   6680\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m thresh \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m lib.no_default:\n",
      "\u001b[31mKeyError\u001b[39m: ['gt_Excretion']"
     ]
    }
   ],
   "source": [
    "gt_df = pd.read_pickle(gt_file)\n",
    "gt_df = gt_df.dropna(subset=f\"gt_{ET}\")\n",
    "gt_df[\"Keyword\"],gt_df[\"Keyword\"].apply(lambda x: 0 if x[0]=='' else 1).value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ac5c04",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d947a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_df.Keyword.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86164cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dictionary = pd.read_pickle(f\"../exports/03_selected_reports_with_event_log_only_dictionary_v2/combined.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa2e514",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dictionary['Events'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1421ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4783 4435 210 10 Event_Name\n",
      "[Unknown]                                  4311\n",
      "[Sleep]                                     114\n",
      "[Pain]                                      112\n",
      "[Family]                                    101\n",
      "[Excretion]                                  66\n",
      "[Eating]                                     21\n",
      "[Sleep, Sleep]                               16\n",
      "[Pain, Pain]                                 16\n",
      "[Pain, Sleep]                                 7\n",
      "[Family, Sleep]                               4\n",
      "[Eating, Eating]                              3\n",
      "[Family, Pain]                                2\n",
      "[Family, Family]                              2\n",
      "[Family, Family, Family, Family]              1\n",
      "[Family, Pain, Sleep, Sleep]                  1\n",
      "[Sleep, Sleep, Sleep]                         1\n",
      "[Eating, Family, Sleep]                       1\n",
      "[Excretion, Excretion]                        1\n",
      "[Family, Family, Family, Family, Sleep]       1\n",
      "[Family, Family, Family]                      1\n",
      "[Pain, Pain, Pain]                            1\n",
      "Name: count, dtype: int64\n",
      "Event_Name\n",
      "Unknown      4311\n",
      "Sleep         164\n",
      "Pain          157\n",
      "Family        124\n",
      "Excretion      68\n",
      "Eating         28\n",
      "Name: count, dtype: int64 Lemma\n",
      "sleep       93\n",
      "sleeping    42\n",
      "asleep      16\n",
      "nap         13\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from glob import glob\n",
    "ET = \"Sleep\"\n",
    "df = pd.read_pickle(glob(f\"../exports/04_groundtruth/P-SET/Generated/{ET}*.pkl\")[0])\n",
    "print(df.UID.nunique(), df.Sentence.nunique(), df.ROW_ID.nunique(), df.SUBJECT_ID.nunique(), df.Event_Name.value_counts())\n",
    "\n",
    "df_exploded = df.explode(['Keyword','Lemma','Event_Name','Keyword_Position'])\n",
    "df_exploded['KUID'] = df_exploded['UID'] + \"_\" + df_exploded['Keyword_Position'].astype(str)\n",
    "print(df_exploded.Event_Name.value_counts(),df_exploded[df_exploded.Event_Name==ET]['Lemma'].value_counts())\n",
    "\n",
    "# df[['SUBJECT_ID', 'LOS_DAYS', 'AGE']].drop_duplicates().mean()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad65b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exploded[df_exploded.Event_Name==\"Sleep\"].to_excel(\"../exports/temp_sleep_keywords.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2bec2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "top10_patients = df_exploded[df_exploded.Event_Name==\"Sleep\"].SUBJECT_ID.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4bfcb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.SUBJECT_ID.isin(top10_patients)].to_excel(\"../exports/temp_top10_patients_all_events.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.10.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
