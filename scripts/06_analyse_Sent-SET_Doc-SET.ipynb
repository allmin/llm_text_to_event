{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "39f31e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"P-SET\"\n",
    "llm_type = \"llama3.1:70b\"\n",
    "prompt_version=3\n",
    "suffix = f\"v{prompt_version}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd235189",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "import numpy as np\n",
    "\n",
    "def plot_confusion_matrices_for_column_pairs(df, gt_col,vis_columns):\n",
    "\n",
    "    n_pairs = len(vis_columns)\n",
    "\n",
    "    # Determine layout: square-ish grid\n",
    "    n_cols = int(np.ceil(np.sqrt(n_pairs)))\n",
    "    n_rows = int(np.ceil(n_pairs / n_cols))\n",
    "\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(5 * n_cols, 5 * n_rows))\n",
    "    axes = axes.flatten()\n",
    "    col1 = gt_col\n",
    "    for idx, col2 in enumerate(vis_columns):\n",
    "        ax = axes[idx]\n",
    "        \n",
    "        # Drop rows with missing values in either column\n",
    "        sub_df = df[[col1, col2]].dropna().copy()\n",
    "        start_length = len(sub_df)\n",
    "        # sub_df = sub_df[sub_df.apply(lambda x: True if (\"_\" not in x[col1] and '_' not in x[col2]) else False, axis=1)]\n",
    "        filter_length = len(sub_df)\n",
    "        # Get confusion matrix\n",
    "        labels = sorted(set(sub_df[col1]) | set(sub_df[col2]))\n",
    "        cm = confusion_matrix(sub_df[col1], sub_df[col2], labels=labels)\n",
    "\n",
    "        # Plot heatmap\n",
    "        sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=labels, yticklabels=labels, ax=ax)\n",
    "        ax.set_title(f\"{col1} vs \\n{col2}\\n strt: {start_length}\\nelim.:{filter_length-start_length}\", fontsize=10)\n",
    "        ax.set_xlabel(col2)\n",
    "        ax.set_ylabel(col1)\n",
    "\n",
    "    # Hide any extra axes\n",
    "    for j in range(len(vis_columns), len(axes)):\n",
    "        fig.delaxes(axes[j])\n",
    "\n",
    "    fig.tight_layout()\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "81cfcadb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /home/asusaiyah/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/asusaiyah/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/asusaiyah/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/asusaiyah/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'most_common_unigram': [('orange', 3),\n",
       "  ('apple', 2),\n",
       "  ('ate', 2),\n",
       "  ('babana', 2)],\n",
       " 'most_common_bigram': [(('apple', 'ate'), 2),\n",
       "  (('orange', 'babana'), 2),\n",
       "  (('ate', 'orange'), 1)],\n",
       " 'most_common_trigram': [(('apple', 'ate', 'orange'), 1)]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from nltk.util import ngrams\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "# Download tokenizer models if not already available\n",
    "nltk.download('punkt')\n",
    "\n",
    "\n",
    "def flatten_list_of_lists(nested_list):\n",
    "    return [item for sublist in nested_list for item in sublist]\n",
    "\n",
    "\n",
    "# Ensure required resources are downloaded\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "def most_frequent_ngrams(sentences, N=5):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    punctuation = set(string.punctuation)\n",
    "\n",
    "    all_unigrams = []\n",
    "    all_bigrams = []\n",
    "    all_trigrams = []\n",
    "\n",
    "    for sentence in sentences:\n",
    "        tokens = word_tokenize(sentence.lower())\n",
    "        # Remove stopwords and punctuation\n",
    "        filtered_tokens = [t for t in tokens if t not in stop_words and t not in punctuation]\n",
    "\n",
    "        all_unigrams.extend(filtered_tokens)\n",
    "        all_bigrams.extend(ngrams(filtered_tokens, 2))\n",
    "        all_trigrams.extend(ngrams(filtered_tokens, 3))\n",
    "\n",
    "    # Count frequencies\n",
    "    unigram_counts = Counter(all_unigrams)\n",
    "    bigram_counts = Counter(all_bigrams)\n",
    "    trigram_counts = Counter(all_trigrams)\n",
    "\n",
    "    # Get top N most common\n",
    "    most_common_unigram = unigram_counts.most_common(N)\n",
    "    most_common_bigram = bigram_counts.most_common(N)\n",
    "    most_common_trigram = trigram_counts.most_common(N)\n",
    "\n",
    "    return {\n",
    "        'most_common_unigram': most_common_unigram,\n",
    "        'most_common_bigram': most_common_bigram,\n",
    "        'most_common_trigram': most_common_trigram\n",
    "    }\n",
    "\n",
    "\n",
    "most_frequent_ngrams([\"apple ate orange\", \"orange at babana\", \"apple ate\", \"orange at babana to\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8fe6b3a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************Sleep************************\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "from itertools import product\n",
    "pd.set_option(\"display.precision\", 3)\n",
    "\n",
    "\n",
    "disagreement_type = \"correct\"\n",
    "\n",
    "def get_time(x):\n",
    "    x = np.array(x)\n",
    "    # Remove NaNs\n",
    "    x = x[~np.isnan(x)]\n",
    "    # If less than 3 values, just return mean\n",
    "    if len(x) < 3:\n",
    "        return np.mean(x)\n",
    "    # Remove outliers using IQR\n",
    "    q1, q3 = np.percentile(x, [25, 75])\n",
    "    iqr = q3 - q1\n",
    "    mask = (x >= q1 - 1.5 * iqr) & (x <= q3 + 1.5 * iqr)\n",
    "    return np.mean(x[mask])\n",
    "\n",
    "def fixnames(ls,suffix,remove):\n",
    "    LS=[]\n",
    "    for s in ls:\n",
    "        s = s.replace(\"_keyword_evidence\",\"_Ki\").replace(\"_example_evidence\",\"_Ei\").replace(\"_no_evidence\",\"\").replace(\"_all_evidence\",\"KiEi\").replace(\"Event_Name_\",'').replace(\"_Events\",'_').replace('_'+remove,\"\")\n",
    "        s = s + \"_\" + suffix\n",
    "        if \"sentence\" in s:\n",
    "            s = s.replace(\"sentence\",\"\")\n",
    "            s = s + \"_Sent-SET\"\n",
    "        elif \"document\" in s:\n",
    "            s = s.replace(\"document\",\"\")\n",
    "            s = s + \"_Doc-SET\"\n",
    "        LS.append(s)\n",
    "    return LS\n",
    "\n",
    "def get_col_suffix(keyword_input, example_input):\n",
    "    col_suffix = \"no\"\n",
    "    if keyword_input and example_input:\n",
    "        col_suffix = \"all\"\n",
    "    elif keyword_input and not example_input:\n",
    "        col_suffix = \"keyword\"\n",
    "    elif not keyword_input and example_input:\n",
    "        col_suffix = \"example\"\n",
    "    return col_suffix\n",
    "\n",
    "LLM_dict = {}\n",
    "llm_models_all = []\n",
    "for keyword_input, example_input in [i for i in product([True,False],[True,False])]: \n",
    "    for input_type in [\"Sent\", \"Doc\"]:\n",
    "        col_suffix = get_col_suffix(keyword_input, example_input)\n",
    "        llm_models_all.append(f\"LLM_Events_{col_suffix}_evidence_{input_type}\")\n",
    "df_both = pd.read_pickle(\"../exports/04b_dictionary_features.pkl\")\n",
    "\n",
    "\n",
    "def ispresent(a,b):\n",
    "    res = []\n",
    "    for i in a:\n",
    "        presence = False\n",
    "        for j in b:\n",
    "            if (i in j) or (j in i):\n",
    "                presence = True\n",
    "                break\n",
    "        res.append(presence)\n",
    "    return res\n",
    "\n",
    "dataset = \"P-SET\"\n",
    "for analysis_type in [\"all\"]: #(M-SET, A-SET, D-SET, F-SET)\n",
    "    for ET in [\"Sleep\"]:\n",
    "        print(f\"********************{ET}************************\")\n",
    "        llm_files = glob(f\"../exports/05b_llm_{llm_type}_{dataset}_{suffix}/{ET}/*.pkl\")\n",
    "        print(llm_files)\n",
    "        try:\n",
    "            gt_file_sent = glob(f\"../exports/04b_groundtruth/{dataset}/Annotated/{ET}_Sentences.pkl\")[0]\n",
    "            gt_file_doc = glob(f\"../exports/04b_groundtruth/{dataset}/Annotated/{ET}_Documents.pkl\")[0]\n",
    "        except IndexError:\n",
    "            print(f\"No ground truth file found for {ET} in ../exports/04b_groundtruth/{dataset}/Annotated/\")\n",
    "            continue    \n",
    "        \n",
    "        llm_files = [i for i in llm_files if \"True\" in i]\n",
    "        llm_files = [i for i in llm_files if \"Sent\" in i]\n",
    "        for file in llm_files:\n",
    "            filename = os.path.basename(file).rstrip('.pkl')\n",
    "            print(filename)\n",
    "            text_type = \"Document\" if \"Document\" in filename else \"Sentence\"\n",
    "            _,attribute_requested = filename.split(\"_\")[-2:]\n",
    "            attribute_requested = eval(attribute_requested)\n",
    "            suffix = \"Ao\" if attribute_requested else \"\"           \n",
    "            print(suffix,attribute_requested,filename)\n",
    "            \n",
    "            if text_type == \"Sentence\":\n",
    "                gt_file = gt_file_sent\n",
    "                id_type = \"UID\"\n",
    "                focus = \"Sent\"\n",
    "                gt_column = f\"Sent_gt_{ET}\"\n",
    "            elif text_type == \"Document\":\n",
    "                gt_file = gt_file_doc\n",
    "                id_type = \"ROW_ID\"\n",
    "                focus = \"Doc\"\n",
    "                gt_column = f\"Doc_gt_{ET}\"\n",
    "            print(f\"****************{text_type}**************\")\n",
    "            gt_df = pd.read_pickle(gt_file)\n",
    "            gt_df[id_type] = gt_df[id_type].astype(str)\n",
    "            df_both[id_type] = df_both[id_type].astype(str)\n",
    "            gt_df = gt_df.dropna(subset=gt_column)\n",
    "            if not attribute_requested:\n",
    "                gt_df[gt_column] = gt_df.apply(lambda x: x[gt_column] if x['negation']==False else False,axis=1)\n",
    "            \n",
    "            gt_df['Lemma'] = gt_df['Lemma'].apply(lambda x: tuple(x))\n",
    "            gt_df[\"is_keyword_present\"] = gt_df[\"Event_Name\"].apply(lambda x: 1 if ET in x else 0)\n",
    "            \n",
    "            id_to_gt = {row[id_type]:row[gt_column] for _,row in gt_df.iterrows()}\n",
    "            id_to_negation = {row[id_type]:row['negation'] for _,row in gt_df.iterrows()}\n",
    "            id_to_key_present = {row[id_type]:row[f\"is_keyword_present\"] for _,row in gt_df.iterrows()}\n",
    "            id_to_lemma = {row[id_type]:row[f\"Lemma\"] for _,row in gt_df.iterrows()}\n",
    "            id_to_comment = {row[id_type]:row[f\"comment\"] for _,row in gt_df.iterrows()}\n",
    "            id_to_dict_time = {row[id_type]:row[f\"Time\"] for _,row in df_both.iterrows()}\n",
    "            \n",
    "            output_folder = f\"../exports/06b_analysis/{ET}\"\n",
    "            os.makedirs(output_folder,exist_ok=True)\n",
    "       \n",
    "            \n",
    "            \n",
    "            df = pd.read_pickle(file)\n",
    "            df[\"num_events_keyword\"] = df[\"Event_Name\"].apply(lambda x: len(x))\n",
    "            df[f\"num_{ET}_keyword\"] = df[\"Event_Name\"].apply(lambda x: len([i for i in x if i == ET]))\n",
    "            df[id_type] = df[id_type].astype(str)\n",
    "            llm_models = [i for i in llm_models_all if i in df]\n",
    "            df[f'{ET}_time'] = df[id_type].apply(lambda x:id_to_dict_time.get(x))\n",
    "            df[\"focus_event\"] = ET\n",
    "            df['negation'] = df[id_type].apply(lambda x:id_to_negation.get(x))\n",
    "            df['comment'] = df[id_type].apply(lambda x:id_to_comment.get(x))\n",
    "            \n",
    "            \n",
    "            df[gt_column] = df[id_type].apply(lambda x:id_to_gt.get(x,None))\n",
    "            df[f\"is_keyword_present\"] = df[id_type].apply(lambda x:id_to_key_present.get(x))\n",
    "            display(df.is_keyword_present.value_counts())\n",
    "            print(df[[gt_column,\"is_keyword_present\"]].value_counts())\n",
    "                        \n",
    "            df[f\"dict_Lemma\"] = df[id_type].apply(lambda x:id_to_lemma.get(x))\n",
    "            df.dropna(subset=gt_column,inplace=True)\n",
    "            df[gt_column] = df[gt_column].astype(int)\n",
    "            \n",
    "            \n",
    "\n",
    "            for col in llm_models:\n",
    "                df[f\"{col}_{ET}_time\"] = df[col].apply(lambda x:x['event_detection_time'])\n",
    "                \n",
    "            if len(df) > 1:\n",
    "                first_row = df.iloc[0]\n",
    "                splittable_columns = [\"Event_Name\"]+[f\"Event_Name_{model}\" for model in llm_models]\n",
    "                disagreement_dfs = []\n",
    "                generated_columns = []\n",
    "\n",
    "                for col in splittable_columns:\n",
    "                    generated_column = f\"{col}_{ET}\"\n",
    "                    df[generated_column] = df[col].apply(lambda x: 1 if ET in x else 0)\n",
    "                    \n",
    "                    generated_columns.append(generated_column)\n",
    "                \n",
    "                f1s, accs, precs, recs, psup, nsup, times, tp, tn, fp, fn = [],[],[],[],[],[],[],[],[],[],[]\n",
    "                \n",
    "                \n",
    "                for col in generated_columns:\n",
    "                    print(col)\n",
    "                    df_temp = df.copy()\n",
    "                    y_gt = df_temp[gt_column]\n",
    "                    LLM_dict[(attribute_requested,gt_column)] = y_gt\n",
    "                    preds = df_temp[col]\n",
    "                    LLM_dict[(attribute_requested,col)] = preds\n",
    "                    f1s.append(f1_score(y_gt, preds))\n",
    "                    accs.append(accuracy_score(y_gt, preds))\n",
    "                    precs.append(precision_score(y_gt, preds, zero_division=0))\n",
    "                    recs.append(recall_score(y_gt, preds))   \n",
    "                    psup.append(sum(y_gt))\n",
    "                    nsup.append(sum(y_gt==0))\n",
    "                    times.append(get_time(df_temp[f\"{col.lstrip('Event_Name_')}_time\"]))\n",
    "                    tn_i, fp_i, fn_i, tp_i = confusion_matrix(y_gt, preds).ravel()\n",
    "                    tp.append(tp_i)\n",
    "                    tn.append(tn_i)\n",
    "                    fp.append(fp_i)\n",
    "                    fn.append(fn_i)\n",
    "                    \n",
    "                    \n",
    "                    if \"all_evidence\" in col:\n",
    "                        col_base = col.lstrip(\"Event_Name_\").rstrip(f\"_{ET}\")\n",
    "                        df[f\"Text_Quote_{col_base}_{ET}\"] = df.apply(lambda x:[t for t,e in zip(x[f\"Text_Quote_{col_base}\"],x[f\"Event_Name_{col_base}\"]) if e==ET],axis=1)\n",
    "                        df[f\"Attribute_{col_base}_{ET}\"] = df.apply(lambda x:[a for a in (x[f\"Attribute_{col_base}\"]) if list(a.keys())[0]==ET],axis=1)\n",
    "                        df[f\"Event_Id_{col_base}\"] = df[col_base].apply(lambda x:[ f\"{eid}={en}|{1 if tq in x['text'] else 0}:{tq}\" for (eid,en,tq) in zip(x['event_id'],x['event'],x['text_quotes'])])\n",
    "                        df[f\"Text_Quote_in_gt\"] = df.apply(lambda x:ispresent(x[f\"Text_Quote_{col_base}_{ET}\"], x['comment'].split('|')), axis=1)\n",
    "\n",
    "                        interesting_columns = [id_type, text_type, gt_column, \n",
    "                                               \"is_keyword_present\",\n",
    "                                               f\"Event_Name_{ET}\", \"comment\", \"negation\", \n",
    "                                               col, \"Text_Quote_in_gt\",\n",
    "                                               f\"Text_Quote_{col_base}_{ET}\",\n",
    "                                               f\"Attribute_{col_base}_{ET}\"]+[i+col_base for i in [\"Event_Name_\",\"Attribute_\",\"Text_Quote_\", \"Event_Id_\",\"Order_\"]] \n",
    "                        \n",
    "                        \n",
    "                        false_positive_samples = df[(df[col]!=df[gt_column])&(df[col]==1)]\n",
    "                        false_positive_samples[interesting_columns].to_excel(f\"../exports/06b_analysis/{ET}/FP_{col}.xlsx\")\n",
    "                        print(\"false_positive_keywords:\",most_frequent_ngrams(flatten_list_of_lists(false_positive_samples[f\"Text_Quote_{col_base}_{ET}\"].to_list()),15))\n",
    "                        false_negative_samples = df[(df[col]!=df[gt_column])&(df[col]==0)]\n",
    "                        false_negative_samples[interesting_columns].to_excel(f\"../exports/06b_analysis/{ET}/FN_{col}.xlsx\")\n",
    "                        # print(\"false_negative_keywords:\",most_frequent_ngrams(flatten_list_of_lists(false_positive_samples[f\"comment\"].to_list()),10))\n",
    "                        true_positive_samples = df[(df[col]==df[gt_column])&(df[gt_column]==1)]\n",
    "                        true_positive_samples[interesting_columns].to_excel(f\"../exports/06b_analysis/{ET}/TP_{col}.xlsx\")\n",
    "                        true_negative_samples = df[(df[col]==df[gt_column])&(df[gt_column]==0)]\n",
    "                        true_negative_samples[interesting_columns].to_excel(f\"../exports/06b_analysis/{ET}/TN_{col}.xlsx\")\n",
    "                        print(\"TP\",len(true_positive_samples),\"TN\",len(true_negative_samples),\"FP\",len(false_positive_samples),\"FN\",len(false_negative_samples),\"%%%%%%%%%%%%%%%%%%%%%%%\")\n",
    "           \n",
    "                results_df = {\"col_name\":generated_columns, \"technique\":fixnames(generated_columns,suffix,ET), \"pos_sup\": psup, \"neg_sup\": nsup, \"f1_score\":f1s, \"precision\":precs, \"recall\":recs, \"TP\":tp, 'TN':tn, 'FP':fp, 'FN':fn, \"time\":times} \n",
    "                results = pd.DataFrame(results_df)   \n",
    "                plot_confusion_matrices_for_column_pairs(df, gt_column,vis_columns=generated_columns)\n",
    "                op_path = f\"{output_folder}/{analysis_type}_{disagreement_type}_{filename}.xlsx\"\n",
    "                df.to_excel(op_path,index=False)\n",
    "                print(f\"file written to {op_path}\")\n",
    "                display(results)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a036f47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sister remained at bedside, sleeping on cot',\n",
       " 'monitor resp sts/sleep apnea',\n",
       " 'wife states patient wears oral airway piece r/t sleep apnea which she will bring in during next visit (sat)',\n",
       " ',daughter in room sleeping overnt-',\n",
       " 'sedation/sleep meds',\n",
       " 'explain to patient about sleep apnea and how patient saturation dropped will affect the heart/body',\n",
       " 'asking for sleeping aid again',\n",
       " 'ccu nursing progress note 1900-0700: 3vd, preop cabgs-\" am i getting a sleeping pill tonight',\n",
       " 'ativan ordered for sleep per anesthesia',\n",
       " 'stated that he was very tired and wanted to sleep around 9pm',\n",
       " 'i stated that he would have to undergo a sleep study for an official diagnosis.patient',\n",
       " 'requesting ativan for sleep',\n",
       " 'social: parents and sister in most of night, parents slept in micu waiting room',\n",
       " 'to facilitate sleep & help control bp',\n",
       " 'patient requesting sleep aid/ \"pill to relax\"',\n",
       " 'ccu npn 2300-0700s:\"i just want to go to sleep',\n",
       " 'propofol off ~0030.patient quite restless at that time with decreasing mvo2 sat->propofol restarted',\n",
       " 'resp: ls clear with dim bases bil. patient placed on mask ventitlation ~ 2-3 hrs overnight',\n",
       " 'bedrest until 9pm']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "false_positive_samples[text_type].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "06630c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[f\"Text_Quote_in_gt\"] = df.apply(lambda x:[((i in j) or (j in i)) for (i,j) in product(x[f\"Text_Quote_{col_base}_{ET}\"], x['comment'])], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c910cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_positive_samples[interesting_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecffd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df[col]==df[gt_column])&(df[col]==1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fcb37fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "f\"{col}_{ET}\", df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c66cad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ea1999",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp[f\"{col.lstrip('Event_Name_')}_time\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9572429c",
   "metadata": {},
   "outputs": [],
   "source": [
    "afile=\"../exports/06_analysis/Sleep/all_correct_Sleep_Sentences_att_True.xlsx\"\n",
    "amodel = \"Event_Name_LLM_Events_all_evidence_Sent_Sleep\"\n",
    "agt = \"Sent_gt_Sleep\"\n",
    "\n",
    "adf = pd.read_excel(afile)\n",
    "adf[adf[amodel]!=adf[agt]][['Sentence',agt,amodel]].to_excel(f\"../exports/temp_false_predictions.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9673e849",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_gt = {row[id_type]:row[gt_column] for _,row in gt_df.iterrows()}\n",
    "set(id_to_gt.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5ea880",
   "metadata": {},
   "outputs": [],
   "source": [
    "row['Sent_ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd7c518",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0165118e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{output_folder}/{analysis_type}_{disagreement_type}_{filename}.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9dd22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "pprint(df_temp[(df_temp[gt_column]==False) & (df_temp[col]==True) & (df_temp[\"Event_Name_Sleep\"]==False)][[id_type,text_type, gt_column, col]].to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c5d350",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770b30c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(file)\n",
    "llm_models = [i for i in llm_models_all if i in df]\n",
    "file,llm_models, df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c8991a",
   "metadata": {},
   "outputs": [],
   "source": [
    "file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b05b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_type =\"Document\" \n",
    "file = f'../exports/05b_llm_llama3.1:70b_P-SET/Sleep/Sleep_{text_type}s_att_True.pkl'\n",
    "llm_df = pd.read_pickle(file)\n",
    "for llm_model in llm_models:\n",
    "    llm_df['tqvalid']=llm_df.apply(lambda x:[i in x[text_type] for i in x[f\"Text_Quotes_{llm_model}\"]], axis=1)\n",
    "    print(llm_model, llm_df['tqvalid'].explode().value_counts())\n",
    "# Text_Quotes_LLM_Events_all_evidence_Sent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a5f862",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ea0800",
   "metadata": {},
   "outputs": [],
   "source": [
    "col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6944b9ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9184bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7b2a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"DOCUMENT\",\"Event_Name_LLM_Events_keyword_evidence_document_Ao\",\"Sentence\" ,\"GT_Sleep\"]].to_excel(\"../exports/temp_result.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38140d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "'dictionary_Sleep_time' in df.columns, llm_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3aff31",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_gt.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33c948e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ac5c04",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d947a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_df.Keyword.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86164cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dictionary = pd.read_pickle(f\"../exports/03b_selected_reports_with_event_log_only_dictionary_v2/combined.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa2e514",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dictionary['Events'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1421ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from glob import glob\n",
    "ET = \"Sleep\"\n",
    "df = pd.read_pickle(glob(f\"../exports/04_groundtruth/P-SET/Generated/{ET}*.pkl\")[0])\n",
    "print(df.UID.nunique(), df.Sentence.nunique(), df.ROW_ID.nunique(), df.SUBJECT_ID.nunique(), df.Event_Name.value_counts())\n",
    "\n",
    "df_exploded = df.explode(['Keyword','Lemma','Event_Name','Keyword_Position'])\n",
    "df_exploded['KUID'] = df_exploded['UID'] + \"_\" + df_exploded['Keyword_Position'].astype(str)\n",
    "print(df_exploded.Event_Name.value_counts(),df_exploded[df_exploded.Event_Name==ET]['Lemma'].value_counts())\n",
    "\n",
    "# df[['SUBJECT_ID', 'LOS_DAYS', 'AGE']].drop_duplicates().mean()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad65b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exploded[df_exploded.Event_Name==\"Sleep\"].to_excel(\"../exports/temp_sleep_keywords.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2bec2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "top10_patients = df_exploded[df_exploded.Event_Name==\"Sleep\"].SUBJECT_ID.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4bfcb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.SUBJECT_ID.isin(top10_patients)].to_excel(\"../exports/temp_top10_patients_all_events.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
