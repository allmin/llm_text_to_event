{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08096dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "def calculate_age(row):\n",
    "    admit = row['ADMITTIME'].to_pydatetime()\n",
    "    dob = row['DOB'].to_pydatetime()\n",
    "    return (admit - dob).days / 365.25\n",
    "\n",
    "\n",
    "\n",
    "admissions = pd.read_pickle(\"../data/ADMISSIONS.pkl\")\n",
    "patients = pd.read_pickle(\"../data/PATIENTS.pkl\")\n",
    "date_cols = ['DOB', 'DOD', 'DOD_HOSP', 'DOD_SSN']\n",
    "patients[date_cols] = patients[date_cols].apply(pd.to_datetime, errors='coerce')\n",
    "print(len(patients))\n",
    "alive_patients_list = patients[patients['DOD'].isna() & patients['DOD_HOSP'].isna() & patients['DOD_SSN'].isna() & (patients['EXPIRE_FLAG'] != 1)]['SUBJECT_ID'].tolist()\n",
    "print(len(alive_patients_list))\n",
    "admissions[\"LOS_DAYS\"] = (admissions[\"DISCHTIME\"] - admissions[\"ADMITTIME\"]).dt.total_seconds() / (24 * 3600)\n",
    "admissions.loc[:,'IS_ALIVE'] = admissions['SUBJECT_ID'].isin(alive_patients_list)\n",
    "subject_id_to_dob = {i:j for (i,j) in zip(patients[\"SUBJECT_ID\"], patients[\"DOB\"])}\n",
    "admissions['DOB'] = admissions['SUBJECT_ID'].map(subject_id_to_dob)\n",
    "admissions['AGE'] = admissions.apply(calculate_age, axis=1)\n",
    "\n",
    "print(admissions[['AGE','LOS_DAYS','IS_ALIVE']].describe())\n",
    "print(admissions['DIAGNOSIS'].value_counts().head(20))\n",
    "hadm_id_to_los_days = {i:j for (i,j) in zip(admissions[\"HADM_ID\"], admissions[\"LOS_DAYS\"])}\n",
    "hadm_id_to_age = {i:j for (i,j) in zip(admissions[\"HADM_ID\"], admissions[\"AGE\"])}\n",
    "hadm_to_is_alive = {i:j for (i,j) in zip(admissions[\"HADM_ID\"], admissions[\"IS_ALIVE\"])}\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Distribution of age at admission:\")\n",
    "admissions['AGE'].hist(bins=311)\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Distribution of length of stay:\")\n",
    "admissions['LOS_DAYS'].hist(bins=100)\n",
    "plt.show()\n",
    "\n",
    "print(\"number of admissions that lasted 7 to 14 days:\", len(admissions[(admissions['LOS_DAYS'] >= 7) & (admissions['LOS_DAYS'] <= 14)]), 'of total admissions:', len(admissions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57340ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "min_perc = np.average([admissions['LOS_DAYS'].rank(ascending=True, method='average', pct=True, numeric_only=True)[i] for i in admissions[admissions['LOS_DAYS']==7].index])\n",
    "max_perc = np.average([admissions['LOS_DAYS'].rank(ascending=True, method='average', pct=True, numeric_only=True)[i] for i in admissions[admissions['LOS_DAYS']==14].index])\n",
    "print(f\"7 days correspond to percentile: {min_perc*100}, and 14 days correspond to {max_perc*100} percentile\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece9a2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analysing negative length of stay\n",
    "neg_los = admissions[(admissions.LOS_DAYS < 0)]\n",
    "neg_los_dead = neg_los[neg_los['IS_ALIVE'] == False]\n",
    "neg_los_alive = neg_los[neg_los['IS_ALIVE'] == True]\n",
    "print(neg_los['IS_ALIVE'].value_counts())\n",
    "print(neg_los_alive[['DIAGNOSIS','DISCHARGE_LOCATION']].value_counts())\n",
    "# conclusion: most of the negative length of stay is due to patients who died before being discharged, and the rest is due to patients who were discharged before being admitted "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3e501a",
   "metadata": {},
   "source": [
    "- Load_notes,\n",
    "- Remove ISERROR,\n",
    "- Select only Categories [\"Nursing\", \"Nursing/other\", \"Physician\", 'Discharge summary']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff44908",
   "metadata": {},
   "outputs": [],
   "source": [
    "notes = pd.read_pickle(\"../data/NOTEEVENTS.pkl\")\n",
    "print(notes.CATEGORY.value_counts())\n",
    "print(len(notes), len(notes.CATEGORY.unique()))\n",
    "selected_categories = [\"Nursing\", \"Nursing/other\"]\n",
    "notes = notes[notes['CATEGORY'].isin(selected_categories)]\n",
    "print(len(notes))\n",
    "notes = notes[notes.ISERROR!=1]\n",
    "print(len(notes))\n",
    "notes = notes[notes.TEXT!=\"\"]\n",
    "print(len(notes))\n",
    "\n",
    "notes_selected = notes.copy()\n",
    "notes_selected.loc[:,'AGE'] = notes_selected['HADM_ID'].map(hadm_id_to_age)\n",
    "notes_selected.loc[:,'LOS_DAYS'] = notes_selected['HADM_ID'].map(hadm_id_to_los_days)\n",
    "notes_selected.loc[:,'IS_ALIVE'] = notes_selected['HADM_ID'].map(hadm_to_is_alive)\n",
    "notes_selected.loc[:,'SUBJECT_ID'] = notes_selected['HADM_ID'].map(admissions.set_index('HADM_ID')['SUBJECT_ID'])\n",
    "print(f\"number of selected notes in {selected_categories}: {len(notes_selected)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15786930",
   "metadata": {},
   "source": [
    "\n",
    "Checking if changing report to lower case helps in number of reports to split into sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd2668e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_repetition_stats(df,column):\n",
    "      row_frequency = df[column].value_counts().reset_index(name='frequency')\n",
    "      repeating_rows = row_frequency[row_frequency['frequency'] > 1]\n",
    "      unique_rows = row_frequency[row_frequency['frequency'] == 1]\n",
    "      print(f\"\"\"{len(repeating_rows)} rows repeat to make {repeating_rows[repeating_rows['frequency'] > 1]['frequency'].sum()} rows\\n\n",
    "            with an additional {len(unique_rows)} unique rows. This makes a total of {len(df)} rows.\"\"\")\n",
    "\n",
    "notes_selected.loc[:,'TEXT_LOWER'] = notes_selected.copy()['TEXT'].str.lower()\n",
    "print(\"TEXT\")\n",
    "get_repetition_stats(notes_selected,'TEXT')\n",
    "print(\"TEXT_LOWER\")\n",
    "get_repetition_stats(notes_selected,'TEXT_LOWER')\n",
    "\n",
    "print(f\"CONCLUSION: Just {61558-60253} reports get benefitted from lower case. but caching is can help 2 percent of the reports.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22544c34",
   "metadata": {},
   "source": [
    "- Remove error strings\n",
    "- Fill abbreviations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3bcec9c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d25887e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n",
    "import spacy, importlib\n",
    "\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.append(parent_dir)\n",
    "    \n",
    "import utils.nlp_tools as nlp_tools\n",
    "nlp_tools = importlib.reload(nlp_tools)\n",
    "# Load the English model (download if you haven't: python -m spacy download en_core_web_lg)\n",
    "nlp = nlp_tools.TextLib(\"en_core_web_lg\")\n",
    "\n",
    "from resources.abbreviations import abbreviation_dict\n",
    "\n",
    "report_counts = 0\n",
    "def replace_abbreviation_and_print_progress(text):\n",
    "    global abbreviation_dict, report_counts\n",
    "    report_counts += 1\n",
    "    if report_counts % 100000 == 0:\n",
    "        print(f\"Processed {report_counts} reports\")\n",
    "    if text is None:\n",
    "        return text\n",
    "    if isinstance(text, str):\n",
    "        text = nlp.replace_abbreviations(text, abbreviation_dict)\n",
    "    return text\n",
    "    \n",
    "print(\"Removing error strings\")\n",
    "notes_selected.loc[:,'TEXT'] = notes_selected['TEXT'].apply(lambda x: nlp.remove_error_strings(x))\n",
    "\n",
    "print(f\"Filling abbreviations on {len(notes_selected)} reports\")\n",
    "notes_selected.loc[:,'TEXT'] = notes_selected['TEXT'].apply(replace_abbreviation_and_print_progress)\n",
    "\n",
    "notes_selected.to_pickle(\"../data/NOTEEVENTS_NURSINGNOTES_REMOVED_ERROR_STRINGS_FILLED_ABBREVIATIONS_new.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4481f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "notes_selected = pd.read_pickle(\"../data/NOTEEVENTS_NURSINGNOTES_REMOVED_ERROR_STRINGS_FILLED_ABBREVIATIONS.pkl\")\n",
    "hadm_to_num_notes = notes_selected.groupby('HADM_ID').size()\n",
    "max_notes_per_day = (notes_selected.groupby(['HADM_ID', 'CHARTDATE']).size().groupby(level='HADM_ID').max())\n",
    "maximum_notes_per_chart_time = (notes_selected.groupby(['HADM_ID', 'CHARTTIME']).size().groupby(level='HADM_ID').max())\n",
    "notes_selected['NUM_NOTES'] = notes_selected['HADM_ID'].map(hadm_to_num_notes)\n",
    "notes_selected['MAX_NOTES_PER_DAY'] = notes_selected['HADM_ID'].map(max_notes_per_day)\n",
    "notes_selected['MAX_NOTES_PER_CHARTTIME'] = notes_selected['HADM_ID'].map(maximum_notes_per_chart_time)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c80d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_quartiles(df, column):\n",
    "    \"\"\"\n",
    "    Calculate the quartiles (Q1, Q2, Q3) for a given column in a DataFrame and return the quartile values along with the subset of rows between Q1 and Q2.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The DataFrame containing the data.\n",
    "        column (str): The column name for which to calculate quartiles.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (q1, q2, q3, mid_df)\n",
    "            q1 (float): 25th percentile value.\n",
    "            q2 (float): Median (50th percentile) value.\n",
    "            q3 (float): 75th percentile value.\n",
    "            mid_df (pd.DataFrame): Subset of df where column values are between q1 and q2 (inclusive).\n",
    "    \"\"\"\n",
    "    q1 = df[column].quantile(0.25)\n",
    "    q2 = df[column].median()\n",
    "    q3 = df[column].quantile(0.75)\n",
    "    mid_df = df[(df[column]>=q1)&(df[column]<=q2)]\n",
    "    num = len(mid_df)\n",
    "    print(f\"{column} Quartiles :\")\n",
    "    print(f\"Q1 (25th percentile): {q1:.2f}\")\n",
    "    print(f\"Q2 (Median):          {q2:.2f}\")\n",
    "    print(f\"Q3 (75th percentile): {q3:.2f}\")\n",
    "    print(f\"Number of rows in this range q1-q3: {num}\")\n",
    "    return q1,q2,q3,mid_df\n",
    "\n",
    "# get_quartiles(notes_selected, 'AGE')\n",
    "get_quartiles(notes_selected, 'LOS_DAYS')\n",
    "plt.figure()\n",
    "plt.title(\"Distribution of number of unique hadm_id per los_days:\")\n",
    "notes_selected[['HADM_ID','LOS_DAYS']].drop_duplicates()['LOS_DAYS'].hist(bins=100)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08b0002",
   "metadata": {},
   "source": [
    "Filter\n",
    "- remove all reports with IS_ERROR\n",
    "- keep only reports from IS_ALIVE admissions\n",
    "- keep only Nursing/other and Nursing\n",
    "- Num reports must atleast be number of days of stay\n",
    "- people age of [18, 89) selected\n",
    "- Length of stay 7 to 14 days ( No reasoning yet)\n",
    "choose between:\n",
    "    - eliminate patients who have atleast two reports with same stortime.\n",
    "    - max num of reports per day <= 5 (too many reports due to show)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec679fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_days = 7\n",
    "max_days = 14\n",
    "# - remove empty TEXT\n",
    "\n",
    "# - remove all reports with IS_ERROR\n",
    "notes_selected = notes_selected[notes_selected['ISERROR'] != 1]\n",
    "# - keep only reports from IS_ALIVE admissions\n",
    "notes_selected = notes_selected[notes_selected['IS_ALIVE'] == True]\n",
    "# - keep only Nursing/other and Nursing\n",
    "notes_selected = notes_selected[notes_selected['CATEGORY'].isin([\"Nursing\", \"Nursing/other\"])]\n",
    "# - Num reports must atleast be number of days of stay\n",
    "notes_selected = notes_selected[notes_selected['NUM_NOTES'] >= notes_selected['LOS_DAYS']]\n",
    "# - people age of [18, 89) selected\n",
    "notes_selected = notes_selected[(notes_selected['AGE'] >= 18) & (notes_selected['AGE'] < 89)]\n",
    "# - Length of stay 5 to 14 days \n",
    "notes_selected = notes_selected[(notes_selected['LOS_DAYS'] >= min_days) & (notes_selected['LOS_DAYS'] <= max_days)]\n",
    "# - max num of reports per day <= 5 (too many reports due to show)\n",
    "notes_selected = notes_selected[notes_selected['MAX_NOTES_PER_DAY'] <= 5]\n",
    "# - max num of reports per chart time == 1 (too many reports due to show)\n",
    "notes_selected = notes_selected[notes_selected['MAX_NOTES_PER_CHARTTIME'] == 1]\n",
    "len(notes_selected), len(notes_selected['HADM_ID'].unique()), len(notes_selected['SUBJECT_ID'].unique())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c45342",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "os.makedirs(\"../exports/images\",exist_ok=True)\n",
    "plt.figure()\n",
    "plt.title(\"Distribution of number of unique hadm_id per age:\")\n",
    "notes_selected[['HADM_ID','AGE']].drop_duplicates()['AGE'].hist(bins=89)\n",
    "plt.savefig(\"../exports/images/age_distribution.png\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Distribution of number of unique hadm_id per los_days:\")\n",
    "notes_selected[['HADM_ID','LOS_DAYS']].drop_duplicates()['LOS_DAYS'].hist(bins=10)\n",
    "plt.savefig(\"../exports/images/los_days_distribution.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b903fa",
   "metadata": {},
   "source": [
    "Extract sentences from the Report. and Clean the sentences as follows:\n",
    "\n",
    "- split sentences at ;\n",
    "- strinp blank leading and training white spaces\n",
    "- convert to lower case\n",
    "- strip off trailing periods\n",
    "- replace\"\\n\"->\"\"\n",
    "- replace double spaces with single spaces\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a081bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sentences(text):\n",
    "    sentences_raw = nlp.sentence_splitter(text,span=False)\n",
    "    sentences = [f\"{sent['headers'][0]}: {sent['text']}\" if sent['headers'] else sent['text'] for sent in sentences_raw]\n",
    "    return sentences \n",
    "\n",
    "def clean_sentences(list_of_sentences):\n",
    "    result_list_of_sentences = []\n",
    "    for full_sentence in list_of_sentences:\n",
    "        splitted_sentences = full_sentence.split(\";\")\n",
    "        for sentence in splitted_sentences:\n",
    "            sentence = sentence.replace(\"\\n\",\"\").strip().lower().rstrip('.').replace(\"  \",\" \").replace(\"\\n\",\"\")\n",
    "            if sentence!= '':\n",
    "                result_list_of_sentences.append(sentence)\n",
    "    return result_list_of_sentences\n",
    "\n",
    "notes_selected['Sentences'] = [[]]*len(notes_selected)\n",
    "print(f\"Time to extract sentences from 100 reports: \")\n",
    "import time\n",
    "start_time = time.time()\n",
    "notes_selected.loc[:100,'Sentences'] = notes_selected['TEXT'].iloc[:100].apply(extract_sentences)\n",
    "end_time = time.time()\n",
    "time_per_100 = end_time - start_time\n",
    "print(f\"Time taken for 100 reports: {time_per_100} seconds\")\n",
    "print(f\" projected time for {len(notes_selected)} reports: {time_per_100 * (len(notes_selected) / 100) / 60} minutes\")\n",
    "print(\"extracting sentences for all reports...\")\n",
    "notes_selected.loc[:,'Sentences'] = notes_selected['TEXT'].apply(extract_sentences)\n",
    "notes_selected['Sentences_Cleaned'] = notes_selected['Sentences'].apply(clean_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6b9577",
   "metadata": {},
   "outputs": [],
   "source": [
    "suffix = f\"{min_days}_{max_days}_days\"\n",
    "notes_selected = notes_selected[notes_selected.Sentences_Cleaned.apply(lambda x: True if len(x)>0 else False)]\n",
    "notes_selected.to_pickle(f\"../exports/filtered_patient_reports_{suffix}.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75176d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "suffix = f\"7_14_days\"\n",
    "notes_selected = pd.read_pickle(f\"../exports/filtered_patient_reports_{suffix}.pkl\")\n",
    "notes_selected[\"Sentences_length\"] = notes_selected['Sentences_Cleaned'].apply(lambda x: len(x))\n",
    "total_sentences = notes_selected['Sentences_length'].sum()\n",
    "print(f\"Total sentences extracted: {total_sentences}\")\n",
    "numberofreports = len(notes_selected)\n",
    "print(f\"Total number of reports: {numberofreports}\")\n",
    "sentences_per_report = notes_selected['Sentences_length'].mean()\n",
    "print(f\"Average number of sentences per report: {sentences_per_report}\")\n",
    "num_patients = notes_selected['HADM_ID'].nunique()\n",
    "print(f\"Total number of patients: {num_patients}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
