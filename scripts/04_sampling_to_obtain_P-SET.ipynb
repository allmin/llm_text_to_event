{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "385ae15b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded file len:  14483\n",
      "After exploding file len:  322079\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "import glob\n",
    "import pandas as pd\n",
    "import random\n",
    "import os, sys\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.append(parent_dir)\n",
    "from config import event_types\n",
    "random.seed(42)\n",
    "pd.set_option('display.max_rows', None)\n",
    "# jupyter nbconvert --to script 04b_combine_results_find_disagreement.ipynb\n",
    "# sudo kill -9 $(nvidia-smi | awk 'NR>8 {print $5}' | grep -E '^[0-9]+$')\n",
    "version = 2\n",
    "from config import event_types\n",
    "\n",
    "def prepare_df(df, type=\"biolord\"):\n",
    "    global event_types\n",
    "    df = df.copy()\n",
    "    print(\"Loaded file len: \",len(df))\n",
    "    df.columns = ['Document' if i=='DOCUMENT' else i for i in df.columns]\n",
    "    df['Sent_ID'] = df['Events'].apply(lambda x: [f\"{i:04d}\" for i in range(len(x))])\n",
    "    df = df.explode([\"Sent_ID\",\"Events\"])\n",
    "    print(\"After exploding file len: \",len(df))\n",
    "    df['UID'] = df['SUBJECT_ID'].astype(str) + \"_\" + df['ROW_ID'].astype(str) + \"_\" + df['Sent_ID'].astype(str)\n",
    "    df = df.dropna(subset=\"Events\")\n",
    "    df['Event_Name'] = df['Events'].apply(lambda x: x['event'])\n",
    "    df['Sentence'] = df['Events'].apply(lambda x: x['text'])\n",
    "    df['Time'] = df['Events'].apply(lambda x: x['event_detection_time'])\n",
    "    \n",
    "    if type == \"dictionary\":\n",
    "        df['Keyword'] = df['Events'].apply(lambda x: x['keyword'])\n",
    "        df['Lemma'] = df['Events'].apply(lambda x: x['lemma'])\n",
    "        df['Keyword_Position'] = df['Events'].apply(lambda x: x['keyword_position'])\n",
    "        \n",
    "    if type == \"biolord\":\n",
    "        df['Similarity'] = df['Events'].apply(lambda x: x['similarity'])\n",
    "        df['Similarity'] = df['Similarity'].apply(lambda x: {k:v for (k,v) in x.items() if k!=\"Alert And Oriented\"})\n",
    "        for ET in event_types:\n",
    "            df[f\"{ET}_similarity\"] = df['Similarity'].apply(lambda x:x[ET])\n",
    "            \n",
    "    return df\n",
    "df_dictionary = prepare_df(pd.read_pickle(f\"../exports/03_selected_reports_with_event_log_only_dictionary_v{version}/combined.pkl\"),type=\"dictionary\")\n",
    "# df_biolord = prepare_df(pd.read_pickle(f\"../exports/selected_reports_with_event_log_only_biolord_v{version}/combined.pkl\"), type = \"biolord\")\n",
    "df_dictionary.to_pickle(\"../exports/04_dictionary_features.pkl\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625e4b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 355 762\n",
      "For event type Pain, N1=10, N2=1, Sentences_with_ET=762, Sentences_without_ET=762, Sentences=1524,Documents_with_ET=145, Documents_without_ET=80, Documents=225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1308264/3259424493.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Documents_with_ET['is_keyword_present'] = True\n",
      "/tmp/ipykernel_1308264/3259424493.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Documents_without_ET['is_keyword_present'] = False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 294\n",
      "For event type Sleep, N1=10, N2=0, Sentences_with_ET=294, Sentences_without_ET=294, Sentences=588,Documents_with_ET=81, Documents_without_ET=121, Documents=202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1308264/3259424493.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Documents_with_ET['is_keyword_present'] = True\n",
      "/tmp/ipykernel_1308264/3259424493.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Documents_without_ET['is_keyword_present'] = False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 430\n",
      "For event type Excretion, N1=10, N2=0, Sentences_with_ET=430, Sentences_without_ET=430, Sentences=860,Documents_with_ET=144, Documents_without_ET=173, Documents=317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1308264/3259424493.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Documents_with_ET['is_keyword_present'] = True\n",
      "/tmp/ipykernel_1308264/3259424493.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Documents_without_ET['is_keyword_present'] = False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 280\n",
      "For event type Eating, N1=10, N2=0, Sentences_with_ET=280, Sentences_without_ET=280, Sentences=560,Documents_with_ET=96, Documents_without_ET=258, Documents=354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1308264/3259424493.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Documents_with_ET['is_keyword_present'] = True\n",
      "/tmp/ipykernel_1308264/3259424493.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Documents_without_ET['is_keyword_present'] = False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 876\n",
      "For event type Family, N1=10, N2=0, Sentences_with_ET=876, Sentences_without_ET=876, Sentences=1752,Documents_with_ET=170, Documents_without_ET=137, Documents=307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1308264/3259424493.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Documents_with_ET['is_keyword_present'] = True\n",
      "/tmp/ipykernel_1308264/3259424493.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Documents_without_ET['is_keyword_present'] = False\n"
     ]
    }
   ],
   "source": [
    "N1 = 10\n",
    "def combine_lists(x):\n",
    "    combined = []\n",
    "    for item in x:\n",
    "        if item:\n",
    "            if isinstance(item, (list, tuple)):\n",
    "                combined.extend(item)\n",
    "            else:\n",
    "                combined.append(item)\n",
    "    combined = [i for i in combined if i]\n",
    "    res = set(combined)\n",
    "    return list(res)\n",
    "from config import event_types\n",
    "import os\n",
    "os.makedirs(\"../exports/04_groundtruth/P-SET/Generated\", exist_ok=True)\n",
    "for ET in event_types:\n",
    "    df_dictionary[f'Event_Name_{ET}'] = df_dictionary['Event_Name'].apply(lambda x: ET in x)\n",
    "    row_id_to_doc_ET = df_dictionary.groupby('ROW_ID')[f'Event_Name_{ET}'].max().to_dict()\n",
    "    df_dictionary[f'Event_Name_{ET}_doc'] = df_dictionary['ROW_ID'].apply(lambda x: row_id_to_doc_ET[x])\n",
    "    people_ranked_by_ET = df_dictionary.groupby('SUBJECT_ID')[f'Event_Name_{ET}'].sum().sort_values(ascending=False).index.tolist()\n",
    "    df_dictionary_topN1 = df_dictionary[df_dictionary['SUBJECT_ID'].isin(people_ranked_by_ET[:N1])]\n",
    "    sentences_w_et_topn1 = df_dictionary_topN1[df_dictionary_topN1[f'Event_Name_{ET}']]\n",
    "    df_dictionary_rest = df_dictionary[~df_dictionary['SUBJECT_ID'].isin(people_ranked_by_ET[:N1])]\n",
    "    sentences_w_et_rest = df_dictionary_rest[df_dictionary_rest[f'Event_Name_{ET}']].sample(len(sentences_w_et_topn1), random_state=42)\n",
    "    Sentences_with_ET = pd.concat([sentences_w_et_topn1, sentences_w_et_rest]).reset_index(drop=True)\n",
    "    Sentences_with_ET['is_keyword_present'] = True\n",
    "    # find N2 such that len(df_dictionary[~df_dictionary['SUBJECT_ID'].isin(people_ranked_by_ET[:N1])]) <= len(Sentences_with_ET)\n",
    "    # N2 = N1\n",
    "    # while len(df_dictionary[(df_dictionary['SUBJECT_ID'].isin(people_ranked_by_ET[:N2])) & ~df_dictionary[f'Event_Name_{ET}']]) >= len(Sentences_with_ET):\n",
    "    #     N2 -= 1\n",
    "    # print(N2, len(df_dictionary[(df_dictionary['SUBJECT_ID'].isin(people_ranked_by_ET[:N2])) & ~df_dictionary[f'Event_Name_{ET}']]), len(Sentences_with_ET))\n",
    "    # df_dictionary_topN2 = df_dictionary[df_dictionary['SUBJECT_ID'].isin(people_ranked_by_ET[:N2])]\n",
    "    Sentences_without_ET = (df_dictionary_topN1[df_dictionary_topN1[f'Event_Name_{ET}']==False]\n",
    "                            .sample(len(Sentences_with_ET), random_state=42))\n",
    "    Sentences_without_ET['is_keyword_present'] = False\n",
    "    Sentences = pd.concat([Sentences_with_ET, Sentences_without_ET]).reset_index(drop=True)\n",
    "    Documents_with_ET = df_dictionary_topN1[df_dictionary_topN1[f'Event_Name_{ET}_doc']]\n",
    "    Documents_with_ET['is_keyword_present'] = True\n",
    "    Documents_without_ET =  df_dictionary_topN1[~df_dictionary_topN1[f'Event_Name_{ET}_doc']]\n",
    "    Documents_without_ET['is_keyword_present'] = False\n",
    "    Documents = pd.concat([Documents_with_ET, Documents_without_ET]).reset_index(drop=True)\n",
    "    Documents['Document'] = Documents['Document'].apply(lambda x: x.lower())\n",
    "    Documents = Documents.groupby('ROW_ID')[[\"Event_Name\",\"Keyword\",\"Document\",\"Lemma\"]].agg(lambda x:combine_lists(x)).reset_index()\n",
    "    Documents['Document'] = [i[0] for i in Documents['Document']]\n",
    "    print(f\"For event type {ET}, N1={N1}, Sentences_with_ET={len(Sentences_with_ET)}, Sentences_without_ET={len(Sentences_without_ET)}, Sentences={len(Sentences)},Documents_with_ET={Documents_with_ET.ROW_ID.nunique()}, Documents_without_ET={Documents_without_ET.ROW_ID.nunique()}, Documents={Documents.ROW_ID.nunique()}\")\n",
    "    # Sentences.to_pickle(f\"../exports/04_groundtruth/P-SET/Generated/{ET}_Sentences.pkl\")\n",
    "    Documents.to_pickle(f\"../exports/04_groundtruth/P-SET/Generated/{ET}_Documents.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "619ba5db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "307"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "23fafbe2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(355, 781)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_dictionary_topN2[~df_dictionary_topN2[f'Event_Name_{ET}']]), len(Sentences_with_ET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "656d23b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ac88677",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Documents' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mDocuments\u001b[49m\u001b[38;5;241m.\u001b[39mDocument\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Documents' is not defined"
     ]
    }
   ],
   "source": [
    "Documents.Document.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fd6e55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Pain*** Pain counts:422\n",
      " Unique Sentences: 5620\n",
      " Unique Reports: 225\n",
      " Unique Patients: 10\n",
      "\n",
      "***Sleep*** Sleep counts:164\n",
      " Unique Sentences: 4783\n",
      " Unique Reports: 210\n",
      " Unique Patients: 10\n",
      "\n",
      "***Excretion*** Excretion counts:229\n",
      " Unique Sentences: 7382\n",
      " Unique Reports: 317\n",
      " Unique Patients: 10\n",
      "\n",
      "***Eating*** Eating counts:152\n",
      " Unique Sentences: 7267\n",
      " Unique Reports: 329\n",
      " Unique Patients: 10\n",
      "\n",
      "***Family*** Family counts:536\n",
      " Unique Sentences: 7910\n",
      " Unique Reports: 328\n",
      " Unique Patients: 10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# N = 10\n",
    "# from config import event_types\n",
    "# import os\n",
    "# os.makedirs(\"../exports/04_groundtruth/P-SET/Generated\", exist_ok=True)\n",
    "# for ET in event_types:\n",
    "#     top_ET = df_dictionary_exploded[df_dictionary_exploded.Event_Name==ET][[\"SUBJECT_ID\",\"Event_Name\"]].value_counts().reset_index().iloc[:N]\n",
    "#     selected_patient_sentences = df_dictionary[df_dictionary.SUBJECT_ID.isin(top_ET['SUBJECT_ID'].tolist())]\n",
    "#     total_ET = top_ET[top_ET.Event_Name==ET]['count'].sum()\n",
    "#     num_sentences = len(selected_patient_sentences.UID.unique())\n",
    "#     num_reports = len(selected_patient_sentences.ROW_ID.unique())\n",
    "#     num_patients = len(selected_patient_sentences.SUBJECT_ID.unique())\n",
    "#     print(f\"***{ET}***\",\n",
    "#           f\"{ET} counts:{total_ET}\\n\",\n",
    "#         # f\"Event counts:\\n{selected_patient_sentences.Event_Name.value_counts()}\\n\"\n",
    "#         f\"Unique Sentences: {num_sentences}\\n\",\n",
    "#         f\"Unique Reports: {num_reports}\\n\",\n",
    "#         f\"Unique Patients: {num_patients}\\n\"\n",
    "#     )\n",
    "#     selected_patient_sentences.to_pickle(f\"../exports/04_groundtruth/P-SET/Generated/04_{ET}_{num_patients}_{num_reports}_{num_sentences}_{total_ET}.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139cbc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_pickle(f\"../exports/04_dictionary_features.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd08621c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top 10 patient sentences: 147\n",
      "top 10 patients sentences without sleep: 4612\n",
      "other patient sentences: 2355\n"
     ]
    }
   ],
   "source": [
    "ET = 'Sleep'\n",
    "df_sentence_with_sleep = (df[df.Event_Name.apply(lambda x: ET in x)])\n",
    "df_sentence_without_sleep = (df[df.Event_Name.apply(lambda x: ET not in x)])\n",
    "top_10_patients = df_sentence_with_sleep.SUBJECT_ID.value_counts().head(10).index.tolist()\n",
    "df_top_10_patient_sentences_with_sleep = df_sentence_with_sleep[df_sentence_with_sleep.SUBJECT_ID.isin(top_10_patients)]\n",
    "df_top_10_patient_sentences_without_sleep = df_sentence_without_sleep[df_sentence_without_sleep.SUBJECT_ID.isin(top_10_patients)]\n",
    "df_not_top_10_patient_sentences = df_sentence_with_sleep[~df_sentence_with_sleep.SUBJECT_ID.isin(top_10_patients)]\n",
    "print(\"top 10 patient sentences:\", len(df_top_10_patient_sentences_with_sleep))\n",
    "print(\"top 10 patients sentences without sleep:\", len(df_top_10_patient_sentences_without_sleep))\n",
    "print(\"other patient sentences:\", len(df_not_top_10_patient_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fd8668d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SUBJECT_ID\n",
       "15883    749\n",
       "23082    604\n",
       "16459    541\n",
       "22673    522\n",
       "4874     489\n",
       "25328    473\n",
       "14995    453\n",
       "3748     361\n",
       "32291    271\n",
       "7042     149\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_top_10_patient_sentences_without_sleep.SUBJECT_ID.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e3e561e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(SUBJECT_ID  3748   4874   7042   14995  15883  16459  22673  23082  25328  \\\n",
       " Event_Name                                                                  \n",
       " False           7      7      6      4     28     18     12     24     10   \n",
       " True            7      9      5     12      8      5     10      8      8   \n",
       " \n",
       " SUBJECT_ID  32291  \n",
       " Event_Name         \n",
       " False           5  \n",
       " True            9  ,\n",
       " Event_Name\n",
       " False    121\n",
       " True      81\n",
       " dtype: int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docid_isevent = df[df.SUBJECT_ID.isin(top_10_patients)].groupby(['ROW_ID','SUBJECT_ID'])['Event_Name'].agg(lambda x: any([ET in j for j in x])).reset_index()\n",
    "docid_isevent[docid_isevent.Event_Name==True]['SUBJECT_ID'].value_counts()\n",
    "res = docid_isevent.groupby([\"Event_Name\", \"SUBJECT_ID\"]).size().unstack(fill_value=0)\n",
    "res, res.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b839b103",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(SUBJECT_ID  3748   4874   7042   14995  15883  16459  22673  23082  25328  \\\n",
       " Event_Name                                                                  \n",
       " False         361    489    149    453    749    541    522    604    473   \n",
       " True           15     17     12     24     13     14     15     12     12   \n",
       " \n",
       " SUBJECT_ID  32291  \n",
       " Event_Name         \n",
       " False         271  \n",
       " True           13  ,\n",
       " Event_Name\n",
       " False    4612\n",
       " True      147\n",
       " dtype: int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentid_isevent = df[df.SUBJECT_ID.isin(top_10_patients)].groupby(['UID','SUBJECT_ID'])['Event_Name'].agg(lambda x: any([ET in j for j in x])).reset_index()\n",
    "sentid_isevent[sentid_isevent.Event_Name==True]['SUBJECT_ID'].value_counts()\n",
    "res = sentid_isevent.groupby([\"Event_Name\", \"SUBJECT_ID\"]).size().unstack(fill_value=0)\n",
    "res, res.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7ec5f72f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "1 453\n",
      "2 942\n",
      "3 1464\n",
      "4 1825\n",
      "5 2366\n",
      "6 2637\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4868, 202)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for N2 in range(7):\n",
    "    res = df_sentence_without_sleep[df_sentence_without_sleep.SUBJECT_ID.isin(top_10_patients[:N2])]\n",
    "    print(N2,len(res))\n",
    "    \n",
    "2366 + 2502, 121 + 81"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "88af41bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "202"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.SUBJECT_ID.isin(top_10_patients)].ROW_ID.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "443daea3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2502"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2355 + 147"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c9485b",
   "metadata": {},
   "source": [
    "df.LOS"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.10.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
